{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [16,12]\n",
    "\n",
    "# from sklearn import manifold\n",
    "from itertools import product, combinations\n",
    "from nltk.corpus import stopwords\n",
    "# from scipy.stats import rankdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to-dos\n",
    "\n",
    "### 1. create a \"make plot\" function\n",
    "### 2. Better model\n",
    "* include words similar to vocab\n",
    "* penalty to stopwords\n",
    "* other models: phonec spelling\n",
    "\n",
    "### 4. Frontend\n",
    "* A \"how it works\" page\n",
    "* \"bring me to\" the link\n",
    "\n",
    "### 5. more content:\n",
    "* more genre\n",
    "* another app (another website)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read\n",
    "books = pd.read_csv('fiction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from gensim.models import KeyedVectors, Phrases\n",
    "# filename = '/Users/weitinglin/Documents/GoogleNews-vectors-negative300.bin'\n",
    "# model = KeyedVectors.load_word2vec_format(filename, binary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a smaller model\n",
    "#### 1. get a list of common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "file = \"/Users/weitinglin/Documents/google-20000-english-usa.txt\"\n",
    "with open(file, 'r') as f:\n",
    "    x = f.readlines()\n",
    "\n",
    "common = [w.strip() for w in x if w.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make my own dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fiction = pd.read_csv('fiction_500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dictionary(books):\n",
    "    temp = []\n",
    "    for b in books:\n",
    "        temp = temp + re.split('[\\W\\s]+', b.lower()) \n",
    "    return set(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict1 = list(make_dictionary(fiction['title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get union of 20k common words and  vocabs in from the 500 books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_common = set(common + dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### make a dictionary\n",
    "common_dict = {}\n",
    "for w in more_common:\n",
    "    if w in model.vocab:\n",
    "        common_dict[w] = model.get_vector(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump(common_dict, open(\"morecommon_dict.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all the above only have to do once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# c_dict = dill.load( open(\"common_dict.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mock up the web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import dill\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# plt.rcParams[\"figure.figsize\"] = [16,12]\n",
    "\n",
    "# from sklearn import manifold\n",
    "from itertools import product, combinations\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_dict = dill.load( open(\"morecommon_dict.pkl\",\"rb\"))# 20k + my_dict\n",
    "# c_dict = dill.load( open(\"common_dict.pkl\",\"rb\"))\n",
    "vocab = c_dict.keys()\n",
    "books = pd.read_csv('fiction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18883"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the string trimming function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_string(S):\n",
    "    '''\n",
    "    trim useless words if string is too long\n",
    "    '''\n",
    "    mystr1 = re.split('[\\W\\s]+', S)\n",
    "    # split at punctuation or space\n",
    "    \n",
    "    mystr =[s.lower() for s in mystr1] \n",
    "    # Remove \"the\", \"a\", \"an\"\n",
    "    nonsense = [\"the\", \"a\", \"an\", \"and\", \"to\",\"on\", \"from\", \"in\", \"by\"]\n",
    "    mystr = [word for word in mystr if word.lower() not in nonsense]\n",
    "        \n",
    "    # remove more\n",
    "    mystr_less = [word for word in mystr if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    if len(mystr_less) > 0 :\n",
    "        mystr = mystr_less\n",
    "    \n",
    "    # remove placeholder \n",
    "    mystr_less = [s for s in mystr if s in vocab]\n",
    "    if len(mystr_less) > 0 :\n",
    "        mystr = mystr_less\n",
    "        \n",
    "    return mystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slaughterhouse', 'five']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = trim_string('Slaughterhouse-Five')\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dragonfly', 'amber']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trim_string('dragonfly in amber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18883"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_dict['banana'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str2mat(instr, limit = 5, placeholder = None):\n",
    "    '''\n",
    "    Convert string to a vector base on average vector of the composing words.\n",
    "    instr: the inpput string\n",
    "    placeholder: for the non-vocabularies\n",
    "    '''\n",
    "    # make a place-holder: mean of three strange words\n",
    "    if placeholder is None:\n",
    "        ph = np.ones(300)* 3\n",
    "    \n",
    "    mystr = trim_string(instr)\n",
    "    \n",
    "    # number of words\n",
    "    L = min(len(mystr), limit) \n",
    "    \n",
    "    ## padding up\n",
    "    sheet = np.ones((300, limit))* 2 \n",
    "    for l in range(L):\n",
    "        if (mystr[l] in vocab):\n",
    "            sheet[:,l] = c_dict[mystr[l]]\n",
    "        else:\n",
    "            sheet[:,l] = ph\n",
    "  \n",
    "    return L, sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, array([[ 3.44238281e-02,  1.77764893e-03,  2.00000000e+00,\n",
       "          2.00000000e+00,  2.00000000e+00],\n",
       "        [ 8.98437500e-02, -3.51562500e-02,  2.00000000e+00,\n",
       "          2.00000000e+00,  2.00000000e+00],\n",
       "        [-2.83203125e-01,  1.12304688e-01,  2.00000000e+00,\n",
       "          2.00000000e+00,  2.00000000e+00],\n",
       "        ...,\n",
       "        [-5.51757812e-02,  1.16699219e-01,  2.00000000e+00,\n",
       "          2.00000000e+00,  2.00000000e+00],\n",
       "        [-4.98046875e-02,  2.08007812e-01,  2.00000000e+00,\n",
       "          2.00000000e+00,  2.00000000e+00],\n",
       "        [-2.45666504e-03, -1.25000000e-01,  2.00000000e+00,\n",
       "          2.00000000e+00,  2.00000000e+00]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str2mat('dragonfly in amber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_mats(M1, M2 , ph = 2, stress = 0.2, penalty = 0.5):\n",
    "    n, limit = M1.shape\n",
    "    L1 = sum(M1[0,:] != 2 ) # lenth of \n",
    "    L2 = sum(M2[0,:] != 2 ) \n",
    "    # trim \n",
    "    M1_trim = M1[:, 0:L1]\n",
    "    M2_trim = M2[:, 0:L2]\n",
    "    \n",
    "    if L1 == 1:\n",
    "        lin_dist = M2_trim - M1_trim\n",
    "        euc_dist = [np.sqrt(sum(lin_dist[:,i]  ** 2)) for i in range(L2)]\n",
    "        dist = min(euc_dist)\n",
    "    elif L2 == 1:\n",
    "        lin_dist = np.tile(M2_trim, L1) - M1_trim\n",
    "        euc_dist = [np.sqrt(sum(lin_dist[:,i]  ** 2)) for i in range(L1)]\n",
    "        # use mean if target is more than 1 words\n",
    "        dist = np.mean(euc_dist) \n",
    "    else:\n",
    "        # \n",
    "        ind_product = list(product(np.arange(L2), repeat=L1)) # select from M2 to match the size of M1\n",
    "        ind_combination = list(combinations(np.arange(L2), L1)) \n",
    "        eucs = []\n",
    "        for p, ind in enumerate(ind_product): # 2, (0,1):\n",
    "            M2_p = M2_trim[:,list(ind)] # permuted M2'\n",
    "            lin_dist = M2_p - M1_trim\n",
    "            euc = [np.sqrt(sum(lin_dist[:,i]  ** 2)) for i in range(L1)]\n",
    "            mean_euc = np.mean(euc)\n",
    "            if ind not in ind_combination:\n",
    "                mean_euc = mean_euc * (stress + 1)\n",
    "            eucs.append(mean_euc)\n",
    "        dist = min(eucs)\n",
    "    # penalty for unequal list\n",
    "    if L2 > L1:\n",
    "        dist = dist +  ((L2 - L1)/(L1 + L2) * penalty)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_strs(S1, S2, limit = 5, placeholder = None):\n",
    "    _, M1 = str2mat(S1, limit = limit)\n",
    "    _, M2 = str2mat(S2, limit = limit)\n",
    "    return compare_mats(M1, M2 , ph = placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fuzzy_find2(mytitle, shelf, maxshow = 10, threshhold = 5):\n",
    "    '''\n",
    "    mytitle: the user input keyword for fuzzy search\n",
    "    shelf: df with column named 'title', find book from\n",
    "    maxshow: the max. number of result return.\n",
    "    threshhold: threshhold of similarity for the \"match\"\n",
    "    '''\n",
    "    dist = []\n",
    "    for s in shelf[\"title\"]:\n",
    "        dist.append(compare_strs(mytitle, s))\n",
    "    dist = np.array(dist)\n",
    "    \n",
    "    fuzzy = np.where(dist < threshhold)[0]\n",
    "    L = len(fuzzy)\n",
    "    if L > maxshow:\n",
    "        rankF = rankdata(dist, method='min') \n",
    "        fuzzy = np.where(rankF <= maxshow)[0]\n",
    "\n",
    "#     return shelf[\"title\"][fuzzy], dist[fuzzy]\n",
    "    return list(shelf[\"title\"][fuzzy]), fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, _ = fuzzy_find2('Butterfly in resin', books, maxshow=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### making the vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "from numpy.random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def string_distance(Slist, limit = 5, placeholder = None):\n",
    "    '''\n",
    "    Return a distance matrix for strings in Slist\n",
    "    '''\n",
    "    N = len(Slist)\n",
    "    dist = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        for j in range(i,N):\n",
    "            dist[i,j] = compare_strs(Slist[i], Slist[j], limit=limit, placeholder=placeholder)\n",
    "            dist[j,i] = dist[i,j]\n",
    "    return dist\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 3.57965192, 4.3279994 ],\n",
       "       [3.57965192, 0.        , 4.13174269],\n",
       "       [4.3279994 , 4.13174269, 0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Strings = ['Butterfly in resin', 'Dragonfly in amber', 'dark tower'] \n",
    "res = string_distance(Strings)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = manifold.MDS(n_components= 2,n_init = 100,random_state=1,dissimilarity='precomputed').fit_transform(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.22271276, -0.44069352],\n",
       "       [ 1.07828975, -1.84136861],\n",
       "       [ 1.14442301,  2.28206213]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suggest_books, _ = fuzzy_find2('Butterfly in resin', books, maxshow=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Great Alone',\n",
       " 'The Alice Network',\n",
       " 'See Me',\n",
       " 'It',\n",
       " 'Call Me by Your Name',\n",
       " 'Cutting for Stone',\n",
       " 'The Brief Wondrous Life of Oscar Wao',\n",
       " 'Lincoln in the Bardo',\n",
       " 'The Tuscan Child',\n",
       " 'The Stand',\n",
       " 'Big Little Lies',\n",
       " 'History Is All You Left Me',\n",
       " 'Still Me',\n",
       " 'All the Light We Cannot See',\n",
       " 'Dragonfly in Amber ',\n",
       " 'At Home in Mitford',\n",
       " 'The Edgar Allan Poe Audio Collection',\n",
       " 'We Are Water',\n",
       " 'Never Too Late',\n",
       " 'Little Big Man',\n",
       " 'Butterfly in resin']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest_books + ['Butterfly in resin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = manifold.MDS(n_components= 2,n_init = 100,random_state=1,dissimilarity='precomputed')\\\n",
    "    .fit_transform(string_distance(suggest_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# suggestion_map function \n",
    "# returns (Y, notation)\n",
    "def suggestion_map(mytitle, shelf, n_init =10, maxshow=20):\n",
    "    # 1. get a list of suggested books\n",
    "    S_list, S_indices = fuzzy_find2(mytitle, shelf, maxshow = maxshow, threshhold = 5)\n",
    "    # 2. calculate distance matrix\n",
    "    Dist = string_distance(S_list + [mytitle], limit = 5, placeholder = None)\n",
    "    # 3. calculate Y\n",
    "    Y = manifold.MDS(n_components= 2, n_init =  n_init, dissimilarity='precomputed')\\\n",
    "                     .fit_transform(Dist)\n",
    "    # 4. get notation\n",
    "    notation = S_list + [mytitle]\n",
    "    \n",
    "    return Y, notation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.99 s ± 157 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Y, notes = suggestion_map('Butterfly in resin', books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.59 s ± 94.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Y, notes = suggestion_map('Butterfly in resin', books,  n_init =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.42 s ± 59.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Y, notes = suggestion_map('Butterfly in resin', books,  maxshow=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    " Dist = string_distance(suggest_books + ['Butterfly in resin'], limit = 5, placeholder = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.01566629, 3.97956625, 3.92991709, 3.76501096, 4.01599256,\n",
       "       3.9704159 , 4.87986749, 3.96628173, 3.89441929, 4.11721266,\n",
       "       4.7780014 , 3.85943067, 3.91511528, 4.71436266, 3.57965192,\n",
       "       4.09137263, 4.715213  , 3.86505552, 3.89154253, 4.63619848,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5-Dist[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10ecadfd0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "sizes = np.ones(len(Y))\n",
    "sizes[-1] = sizes[-1] * 2\n",
    "plt.scatter(Y[:,0], Y[:,1], s = 5-Dist[-1,:], c=\"g\", alpha=0.5, marker=r'$\\clubsuit$',\n",
    "            label=\"Luck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDP/A+FyGV/crnW9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ec91d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = np.ones(20) * 0.01\n",
    "sizes[-1] = sizes[-1] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.02])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "colar = [\"#1f1b99\" for i in sizes]\n",
    "colar[-1] = \"#f442c5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.463936909774312"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(Y[:,0]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yin = Y\n",
    "xmock = max(Yin[:,0]) + 1\n",
    "ymock = max(Yin[:,1]) + 1\n",
    "Y2 = np.concatenate((np.array([xmock, ymock]).reshape(1,2),  Yin), axis=0) \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 2)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'The Great Alone', 'The Alice Network', 'See Me', 'It',\n",
       "       'Call Me by Your Name', 'Cutting for Stone',\n",
       "       'The Brief Wondrous Life of Oscar Wao', 'Lincoln in the Bardo',\n",
       "       'The Tuscan Child', 'The Stand', 'Big Little Lies',\n",
       "       'History Is All You Left Me', 'Still Me',\n",
       "       'All the Light We Cannot See', 'Dragonfly in Amber ',\n",
       "       'At Home in Mitford', 'The Edgar Allan Poe Audio Collection',\n",
       "       'We Are Water', 'Never Too Late', 'Little Big Man'], dtype='<U36')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((np.array([\"\"]),  suggest_books), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [16,12]\n",
    "\n",
    "from sklearn import manifold\n",
    "from itertools import product\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.stats import rankdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read\n",
    "books = pd.read_csv('fiction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from gensim.models import KeyedVectors\n",
    "# filename = '/Users/weitinglin/Documents/GoogleNews-vectors-negative300.bin'\n",
    "# model = KeyedVectors.load_word2vec_format(filename, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_string(S):\n",
    "    '''\n",
    "    trim useless words if string is too long\n",
    "    '''\n",
    "    mystr1 = re.split('[\\W\\s]+', S)\n",
    "    # split at punctuation or space\n",
    "    \n",
    "    mystr =[s.lower() for s in mystr1] \n",
    "    # Remove \"the\", \"a\", \"an\"\n",
    "    nonsense = [\"the\", \"a\", \"an\", \"and\", \"to\",\"on\", \"from\", \"in\", \"by\"]\n",
    "    mystr = [word for word in mystr if word.lower() not in nonsense]\n",
    "        \n",
    "    # remove more\n",
    "    mystr_less = [word for word in mystr if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    if len(mystr_less) > 0 :\n",
    "        mystr = mystr_less\n",
    "    \n",
    "    # remove placeholder \n",
    "    mystr_less = [s for s in mystr if s in model.vocab]\n",
    "    if len(mystr_less) > 0 :\n",
    "        mystr = mystr_less\n",
    "    \n",
    "    return mystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slaughterhouse', 'five']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = trim_string('Slaughterhouse-Five')\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str2mat(instr, limit = 5, placeholder = None):\n",
    "    '''\n",
    "    Convert string to a vector base on average vector of the composing words.\n",
    "    instr: the inpput string\n",
    "    placeholder: for the non-vocabularies\n",
    "    '''\n",
    "    # make a place-holder: mean of three strange words\n",
    "    if placeholder is None:\n",
    "        ph = (model.get_vector(\"Ka_wai\") + \\\n",
    "              model.get_vector(\"Chief_Carla_Piluso\") + model.get_vector(\"Marc_Andre_Bergeron\"))/1\n",
    "    \n",
    "    mystr = trim_string(instr)\n",
    "    \n",
    "    # number of words\n",
    "    L = min(len(mystr), limit) \n",
    "    \n",
    "    ## padding up\n",
    "    sheet = np.ones((300, limit))* 2 \n",
    "    for l in range(L):\n",
    "        if (mystr[l] in model.vocab):\n",
    "            sheet[:,l] = model.get_vector(mystr[l])\n",
    "        else:\n",
    "            sheet[:,l] = ph\n",
    "  \n",
    "    return L, sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_mats(M1, M2 , ph = 2):\n",
    "    n, limit = M1.shape\n",
    "    L1 = sum(M1[0,:] != 2 ) # lenth of \n",
    "    L2 = sum(M2[0,:] != 2 ) \n",
    "    # trim \n",
    "    M1_trim = M1[:, 0:L1]\n",
    "    M2_trim = M2[:, 0:L2]\n",
    "    \n",
    "    if L1 == 1:\n",
    "        lin_dist = M2_trim - M1_trim\n",
    "        euc_dist = [np.sqrt(sum(lin_dist[:,i]  ** 2)) for i in range(L2)]\n",
    "        dist = min(euc_dist)\n",
    "    elif L2 == 1:\n",
    "        lin_dist = np.tile(M2_trim, L1) - M1_trim\n",
    "        euc_dist = [np.sqrt(sum(lin_dist[:,i]  ** 2)) for i in range(L1)]\n",
    "        # use mean if target is more than 1 words\n",
    "        dist = np.mean(euc_dist) \n",
    "    else:\n",
    "        inds = list(product(np.arange(L2), repeat=L1)) # select from M2 to match the size of M1\n",
    "        eucs = []\n",
    "        for p, ind in enumerate(inds): # 2, (0,1):\n",
    "            M2_p = M2_trim[:,list(ind)] # permuted M2'\n",
    "            lin_dist = M2_p - M1_trim\n",
    "            euc = [np.sqrt(sum(lin_dist[:,i]  ** 2)) for i in range(L1)]\n",
    "            eucs.append(np.mean(euc))\n",
    "        dist = min(eucs)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_strs(S1, S2, limit = 5, placeholder = None):\n",
    "    _, M1 = str2mat(S1, limit = limit)\n",
    "    _, M2 = str2mat(S2, limit = limit)\n",
    "    return compare_mats(M1, M2 , ph = placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_strs('dark', 'Dark tower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7817500703577505"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_strs('dark tower', 'ddddddd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.750284740905288"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_strs('dark tower', 'dragonfly in amber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.32972583831502"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_strs('the dark tower', 'black castle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fuzzy_find2(mytitle, shelf, maxshow = 10, threshhold = 5):\n",
    "    '''\n",
    "    mytitle: the user input keyword for fuzzy search\n",
    "    shelf: df with column named 'title', find book from\n",
    "    maxshow: the max. number of result return.\n",
    "    threshhold: threshhold of similarity for the \"match\"\n",
    "    '''\n",
    "    dist = []\n",
    "    for s in shelf[\"title\"]:\n",
    "        dist.append(compare_strs(mytitle, s))\n",
    "    dist = np.array(dist)\n",
    "    \n",
    "    fuzzy = np.where(dist < threshhold)[0]\n",
    "    L = len(fuzzy)\n",
    "    if L > maxshow:\n",
    "        rankF = rankdata(dist, method='min') \n",
    "        fuzzy = np.where(rankF <= maxshow)[0]\n",
    "#         print(rankF)\n",
    "#         print(fuzzy) \n",
    "#     return fuzzy\n",
    "    return shelf[\"title\"][fuzzy], dist[fuzzy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14                                      It\n",
       " 26    The Brief Wondrous Life of Oscar Wao\n",
       " 32                    Lincoln in the Bardo\n",
       " 38                        The Tuscan Child\n",
       " 64                     Dragonfly in Amber \n",
       " Name: title, dtype: object,\n",
       " array([3.61952804, 3.44184083, 3.45750671, 3.52358933, 3.57965192]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzy_find2('butterfly in resin', books, maxshow=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
